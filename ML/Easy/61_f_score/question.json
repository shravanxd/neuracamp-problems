{
    "qid": 61,
    "title": "Implement F-Score Calculation for Binary Classification",
    "qtext": "## Problem Statement\n\nImplement a function to calculate the F-Score for a binary classification task. The F-Score is a metric that combines both Precision and Recall, providing a balanced measure of a model's performance.\n\n### Function Signature\n\n```python\nf_score(y_true: np.ndarray, y_pred: np.ndarray, beta: float) -> float\n```\n\n### Definitions\n\n- **Precision**: The ratio of true positive predictions to the total number of positive predictions made. It is calculated as:\n  $$ \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}} $$\n\n- **Recall**: The ratio of true positive predictions to the total number of actual positive instances. It is calculated as:\n  $$ \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}} $$\n\n- **F-Score**: A measure that combines Precision and Recall using a weighted harmonic mean. It is calculated as:\n  $$ F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{(\\beta^2 \\cdot \\text{Precision}) + \\text{Recall}} $$\n\n### Constraints\n\n- $y_{true}$ and $y_{pred}$ are numpy arrays of binary values (0 or 1).\n- $\\beta$ is a positive float.\n- The function should return the F-Score rounded to three decimal places.\n\n## Example 1\n\n**Input:**\n```python\ny_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([1, 0, 1, 0, 0, 1])\nbeta = 1\n```\n\n**Output:**\n```python\n0.857\n```\n\n**Explanation:**\n- True Positives (TP) = 3\n- False Positives (FP) = 0\n- False Negatives (FN) = 1\n- Precision = 3 / (3 + 0) = 1.0\n- Recall = 3 / (3 + 1) = 0.75\n- F1-Score = 2 * (1.0 * 0.75) / (1.0 + 0.75) = 0.857",
    "inputFormat": "```python\ny_true = np.array([...])\ny_pred = np.array([...])\nbeta = float\n```",
    "outputFormat": "```python\nfloat  # F-Score rounded to three decimal places\n```",
    "reason": "The F-Score for the binary classification task is calculated using the true labels, predicted labels, and beta value.",
    "learnAbout": "### Understanding the F-Score\n\nThe F-Score, also known as the F-Measure, is a metric used to evaluate the accuracy of a binary classification model. It is particularly useful when the class distribution is imbalanced. The F-Score is the harmonic mean of Precision and Recall, which means it gives equal weight to both metrics when $\\beta = 1$, known as the F1-Score. By adjusting $\\beta$, you can emphasize either Precision (when $\\beta < 1$) or Recall (when $\\beta > 1$), making it a flexible tool for model evaluation. The harmonic mean is used instead of the arithmetic mean because it punishes extreme values, ensuring that both Precision and Recall need to be reasonably high for a good F-Score."
}