{
    "qid": 61,
    "title": "Implement F-Score Calculation for Binary Classification",
    "qtext": "Task: Implement F-Score Calculation for Binary Classification\n\nYour task is to implement a function that calculates the F-Score for a binary classification task. The F-Score combines both Precision and Recall into a single metric, providing a balanced measure of a model's performance.\n\nWrite a function f_score(y_true, y_pred, beta) where:\n\ny_true: A numpy array of true labels (binary).\ny_pred: A numpy array of predicted labels (binary).\nbeta: A float value that adjusts the importance of Precision and Recall. When beta=1, it computes the F1-Score, a balanced measure of both Precision and Recall.\n\nThe function should return the F-Score rounded to three decimal places.\n\nExample:\nInput:\ny_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([1, 0, 1, 0, 0, 1])\nbeta = 1\n\nprint(f_score(y_true, y_pred, beta))\nOutput:\n0.857\n\nReasoning:\nThe F-Score for the binary classification task is calculated using the true labels, predicted labels, and beta value.",
    "inputFormat": "y_true = np.array([1, 0, 1, 1, 0, 1])\ny_pred = np.array([1, 0, 1, 0, 0, 1])\nbeta = 1",
    "outputFormat": "0.857",
    "reason": "The F-Score for the binary classification task is calculated using the true labels, predicted labels, and beta value.",
    "learnAbout": "Understanding F-Score in Classification\n\nF-Score, also called F-measure, is a measure of predictive performance that's calculated from the Precision and Recall metrics.\n\n**Mathematical Definition**\n\nThe \\( F_\\beta \\) score applies additional weights, valuing one of precision or recall more than the other. When \\( \\beta \\) equals 1, also known as the F1-Score, it symmetrically represents both precision and recall in one metric. The F-Score can be calculated using the following formula:\n\n$$\nF_\\beta = (1 + \\beta^2) \\times \\frac{\\text{precision} \\times \\text{recall}}{(\\beta^2 \\times \\text{precision}) + \\text{recall}}\n$$\n\nWhere:\n\n- **Recall**: The number of true positive results divided by the number of all samples that should have been identified as positive.\n- **Precision**: The number of true positive results divided by the number of all samples predicted to be positive, including those not identified correctly.\n\n**Implementation Instructions**\n\nIn this problem, you will implement a function to calculate the F-Score given the true labels, predicted labels, and the Beta value of a binary classification task. The results should be rounded to three decimal places.\n\n**Special Case:**\nIf the denominator is zero, the F-Score should be set to 0.0 to avoid division by zero."
  }
  