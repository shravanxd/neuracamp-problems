{
    "qid": 17,
    "title": "K-Means Clustering",
    "qtext": "# K-Means Clustering\n\n## Description\n\nImplement the K-Means clustering algorithm in Python. The algorithm partitions a set of $n$ data points into $k$ distinct clusters. Each cluster is represented by its centroid, which is the mean of the points in that cluster. The goal is to minimize the variance within each cluster.\n\n### Function Signature\n```python\ndef k_means_clustering(points: List[Tuple[float, float]], k: int, initial_centroids: List[Tuple[float, float]], max_iterations: int) -> List[Tuple[float, float]]:\n```\n\n### Parameters\n- `points`: A list of tuples, where each tuple represents a point in a multi-dimensional space (e.g., $(x, y)$ for 2D points).\n- `k`: An integer representing the number of clusters to form.\n- `initial_centroids`: A list of tuples representing the initial centroid positions.\n- `max_iterations`: An integer specifying the maximum number of iterations to perform.\n\n### Returns\n- A list of tuples representing the final centroids of the clusters, rounded to the nearest fourth decimal place.\n\n### Example 1\n\n**Input:**\n```python\npoints = [(1, 2), (1, 4), (1, 0), (10, 2), (10, 4), (10, 0)]\nk = 2\ninitial_centroids = [(1, 1), (10, 1)]\nmax_iterations = 10\n```\n\n**Output:**\n```python\n[(1.0, 2.0), (10.0, 2.0)]\n```\n\n**Explanation:**\nThe algorithm iteratively assigns each point to the nearest centroid, then recalculates the centroids as the mean of the assigned points. This process is repeated until convergence or the maximum number of iterations is reached. The final centroids approximate the means of the two clusters.\n\n### Constraints\n- $1 \\leq k \\leq n$\n- $1 \\leq \\text{len(points)} \\leq 10^4$\n- Each coordinate of the points and centroids is a float within the range $-10^4 \\leq x, y \\leq 10^4$\n- $1 \\leq \\text{max_iterations} \\leq 1000$\n\n## Learning\nK-Means clustering is an unsupervised learning algorithm used to partition data into $k$ clusters. The algorithm works by initializing $k$ centroids, assigning each point to the nearest centroid, and then recalculating the centroids as the mean of the points assigned to them. This process is repeated until the centroids no longer change significantly or a maximum number of iterations is reached. The objective is to minimize the sum of squared distances from each point to its assigned centroid, effectively reducing the intra-cluster variance.\n\nK-Means is sensitive to the initial placement of centroids and may converge to a local minimum. It is often used in applications such as image compression, market segmentation, and pattern recognition.\n",
    "inputFormat": "points = [(1, 2), (1, 4), (1, 0), (10, 2), (10, 4), (10, 0)], k = 2, initial_centroids = [(1, 1), (10, 1)], max_iterations = 10",
    "outputFormat": "[(1.0, 2.0), (10.0, 2.0)]",
    "reason": "Given the initial centroids and a maximum of 10 iterations, the points are clustered around these points, and the centroids are updated to the mean of the assigned points, resulting in the final centroids which approximate the means of the two clusters. The exact number of iterations needed may vary, but the process will stop after 10 iterations at most.",
    "learnAbout": "K-Means clustering is an unsupervised learning algorithm used to partition data into $k$ clusters. The algorithm works by initializing $k$ centroids, assigning each point to the nearest centroid, and then recalculating the centroids as the mean of the points assigned to them. This process is repeated until the centroids no longer change significantly or a maximum number of iterations is reached. The objective is to minimize the sum of squared distances from each point to its assigned centroid, effectively reducing the intra-cluster variance.\n\nK-Means is sensitive to the initial placement of centroids and may converge to a local minimum. It is often used in applications such as image compression, market segmentation, and pattern recognition."
}