{
    "qid": 24,
    "title": "Single Neuron",
    "qtext": "# Single Neuron with Sigmoid Activation\n\n## Problem Description\n\nImplement a Python function that simulates a single neuron using a sigmoid activation function for binary classification. The function should handle multidimensional input features. Given a set of feature vectors, corresponding binary labels, neuron weights, and a bias term, the function should compute the predicted probabilities and the mean squared error (MSE) between the predictions and the true labels.\n\n### Mathematical Formulation\n\nFor each feature vector $\\mathbf{x}_i$, the neuron computes the weighted sum $z_i$ as follows:\n\n$$ z_i = \\mathbf{w} \\cdot \\mathbf{x}_i + b $$\n\nwhere $\\mathbf{w}$ is the weight vector, $\\mathbf{x}_i$ is the feature vector, and $b$ is the bias.\n\nThe sigmoid activation function is applied to $z_i$ to obtain the predicted probability $\\hat{y}_i$:\n\n$$ \\hat{y}_i = \\sigma(z_i) = \\frac{1}{1 + e^{-z_i}} $$\n\nThe mean squared error (MSE) between the predicted probabilities $\\hat{y}_i$ and the true labels $y_i$ is calculated as:\n\n$$ \\text{MSE} = \\frac{1}{n} \\sum_{i=1}^{n} (\\hat{y}_i - y_i)^2 $$\n\n### Constraints\n- The feature vectors, weights, and bias are all real numbers.\n- The number of features in each vector matches the number of weights.\n- The labels are binary (0 or 1).\n\n## Example 1\n\n**Input:**\n```python\nfeatures = [[0.5, 1.0], [-1.5, -2.0], [2.0, 1.5]]\nlabels = [0, 1, 0]\nweights = [0.7, -0.4]\nbias = -0.1\n```\n\n**Output:**\n```python\n([0.4626, 0.4134, 0.6682], 0.3349)\n```\n\n**Explanation:**\nFor each feature vector, compute the weighted sum, apply the sigmoid function to get the predicted probability, and calculate the MSE against the true labels.\n",
    "inputFormat": "```python\nfeatures = [[float, ...], ...]\nlabels = [int, ...]\nweights = [float, ...]\nbias = float\n```",
    "outputFormat": "```python\n([float, ...], float)\n```",
    "reason": "The neuron combines inputs linearly with weights and bias, applies the sigmoid activation to produce probabilities, and the mean squared error evaluates the prediction quality against the true labels.",
    "learnAbout": "### Sigmoid Activation Function\n\nThe sigmoid function is a mathematical function that maps any real-valued number into the range (0, 1). It is defined as:\n\n$$ \\sigma(x) = \\frac{1}{1 + e^{-x}} $$\n\nThis function is commonly used in binary classification problems as it can convert the output of a linear equation into a probability. The sigmoid function is differentiable, which makes it suitable for optimization algorithms like gradient descent. Its S-shaped curve helps in squashing the output to a range between 0 and 1, making it interpretable as a probability."
}